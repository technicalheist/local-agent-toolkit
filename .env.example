# Local Agent Toolkit Environment Configuration
# Copy this file to .env and fill in your values

# Agent Configuration
# Choose which AI agent to use: OLLAMA or OPENAI
CURRENT_AGENT=OLLAMA

# Ollama Configuration
# Model name to use with Ollama (e.g., llama3.1, codellama, etc.)
OLLAMA_MODEL=llama3.1
# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# OpenAI Configuration
# Your OpenAI API key (required only if using OPENAI agent)
OPENAI_API_KEY=your_openai_api_key_here
# OpenAI API base URL (optional, for custom endpoints)
OPENAI_API_BASE=https://api.openai.com/v1
# OpenAI model to use (optional, defaults to gpt-4 in the code)
OPENAI_MODEL=gpt-4

# Legacy/Alternative API Configuration
API_BASE_URL=http://localhost:5000

# Tool and Processing Configuration
# Maximum iterations for tool calls to prevent infinite loops
MAX_ITERATIONS=25

# Directory for file operations (optional, defaults to current directory)
WORK_DIRECTORY=./

# Logging Configuration (optional)
LOG_LEVEL=INFO
LOG_FILE=agent.log

# Advanced Configuration (optional)
# Maximum tool call depth to prevent infinite loops
MAX_TOOL_CALLS=10
# Request timeout in seconds
REQUEST_TIMEOUT=30